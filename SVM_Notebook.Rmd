```{r} 
setwd("/Users/tz240/Desktop/Tims/School/Regis/MSDS_692")
Fraud_Data <- read.csv("Fraud_Data.CSV")
library(dplyr)
library(ggplot2)
library(ggExtra)
library(stringr)
library(caret)
library(e1071)
```

```{r}
#Null data?
sum(complete.cases(Fraud_Data)) #Provides count of non-null values

```

```{r}
sum(!complete.cases(Fraud_Data)) #Provides count of null values
```

```{r}
#Data types of columns
str(Fraud_Data)
```

```{r}
#High Level Overview all all data
summary(Fraud_Data)
```

```{r}
#High Level Overview of fraud data only
JustFraud <- subset(Fraud_Data, isFraud == "1")
JustFraud <- JustFraud[,c(1:9)]
summary(JustFraud)
```

```{r}
#High Level Overview of data that is not fraud
JustNonFraud <- subset(Fraud_Data, isFraud == "0")
JustNonFraud <- JustNonFraud[,c(1:9)]
summary(JustNonFraud)
```
```{r}
madfigures <- data.frame(MADstep = mad(Fraud_Data$step),
                         MADamount = mad(Fraud_Data$amount),
                         MADoldBalanceOrg = mad(Fraud_Data$oldbalanceOrg),
                         MADnewBalanceOrig = mad(Fraud_Data$newbalanceOrig),
                         MADoldBalanceDest = mad(Fraud_Data$oldbalanceDest),
                         MADnewBalanceDest = mad(Fraud_Data$newbalanceDest))
madJustFraud <- data.frame(MADstep = mad(JustFraud$step),
                         MADamount = mad(JustFraud$amount),
                         MADoldBalanceOrg = mad(JustFraud$oldbalanceOrg),
                         MADnewBalanceOrig = mad(JustFraud$newbalanceOrig),
                         MADoldBalanceDest = mad(JustFraud$oldbalanceDest),
                         MADnewBalanceDest = mad(JustFraud$newbalanceDest))
madJustNonFraud <- data.frame(MADstep = mad(JustNonFraud$step),
                         MADamount = mad(JustNonFraud$amount),
                         MADoldBalanceOrg = mad(JustNonFraud$oldbalanceOrg),
                         MADnewBalanceOrig = mad(JustNonFraud$newbalanceOrig),
                         MADoldBalanceDest = mad(JustNonFraud$oldbalanceDest),
                         MADnewBalanceDest = mad(JustNonFraud$newbalanceDest))
bind_rows(madfigures, madJustFraud, madJustNonFraud)
```
```{r}
isfraud <- table(Fraud_Data$isFraud)
isflagfraud <- table(Fraud_Data$isFlaggedFraud)
bind_rows(isfraud, isflagfraud)
```
```{r}
#Visual of fraud against amount transferred
ggplot(Fraud_Data, aes(x = newbalanceOrig, 
                       y = amount, 
                       color = isFraud, 
                       shape = type)) +
  geom_point()
```

```{r}
### Hours of transactions ###
step <- table(Fraud_Data$step)
step <- as.data.frame(step)
step <- data.frame(hours = step$Var1,
                   frequency = step$Freq)
hist(Fraud_Data$step, 
     main = "# of Transactions per Hr", 
     xlab = "Hour", 
     ylab = "Frequency", 
     col = "Dark Green", 
     breaks = c(0,24,48,72,96,120,144,168,192,216,240,264,288,
                312,336,360,384,408,432,456,480,504,528,552,
                576,600,624,648,672,696,720,744))
```

```{r}
plot(step)
```

```{r}
### Type ###
Type <- table(Fraud_Data$type)
Type
```

```{r}
#type Plot
percent <- round(100*Type/sum(Type),1)
pie(Type, labels = percent, main = "Transaction Type", col = rainbow(length(Type)))
legend("topright", c("Cash IN", "Cash Out", "Debit", "Payment", "Transfers"), cex = 1, fill = rainbow(length(Type)))
```

```{r}
##Amount, Fraud, Type ##
Amount100 <- subset(Fraud_Data, amount <= 100000)
sp <- ggplot(Amount100, aes(Amount100$amount)) +
  geom_histogram(col = "red",
                 aes(fill = ..count..),
                 bins = 5) +
  scale_fill_gradient("Count", low = "green", high = "red")
sp + facet_grid(isFraud ~ type, scales = "free") + 
                 labs(x="Amount (<= 100,000)")
```

```{r}
## Old to New Bal Original ##
ap <- ggplot(Fraud_Data, aes(x = newbalanceOrig, y = oldbalanceOrg)) +
  geom_point(shape = 1)
ap + facet_grid(isFraud ~ type, scales = "free")
```

```{r}
#correlation
library(reshape)
corFraud <- Fraud_Data[,c(3,5,6,8,9)]
roundFraud <- round(cor(corFraud),2)

get_lower_tri<-function(roundFraud){
  roundFraud[upper.tri(roundFraud)] <- NA
  return(roundFraud)
}
# Get upper triangle of the correlation matrix
get_upper_tri <- function(roundFraud){
  roundFraud[lower.tri(roundFraud)]<- NA
  return(roundFraud)
}

upper_tri <- get_upper_tri(roundFraud)
melted_fraud <- melt(upper_tri, na.rm = TRUE)

ggplot(data = melted_fraud, aes(X2, X1, fill = value))+
  geom_tile(color = "white")+
  scale_fill_gradient2(low = "Dark Red", high = "Dark Green", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Pearson\nCorrelation") +
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1))+
  coord_fixed()
```

```{r}
#Cleaning dataset
library(stringr)

svm_fraud <- data.frame(hours = Fraud_Data$step,
                        type = as.numeric(Fraud_Data$type),
                        amount = Fraud_Data$amount,
                        transaction_start = str_sub(Fraud_Data$nameOrig,1,1),
                        old_balance_orig = Fraud_Data$oldbalanceOrg,
                        new_balance_orig = Fraud_Data$newbalanceOrig,
                        transaction_end = str_sub(Fraud_Data$nameDest,1,1),
                        old_balance_dest = Fraud_Data$oldbalanceDest,
                        new_balance_dest = Fraud_Data$newbalanceDest,
                        fraud = factor(Fraud_Data$isFraud, levels = c("0", "1"), labels = c("No", "Yes")),
                        fraud_flag = factor(Fraud_Data$isFlaggedFraud, levels = c("0", "1"), labels = c("No", "Yes")))
svm_fraud$transaction_end <- as.numeric(svm_fraud$transaction_end)
svm_fraud$transaction_start <- as.numeric(svm_fraud$transaction_start)
str(svm_fraud)
```

```{r}
#Fraud data is less than 1 percent of all data
svm_fraud_2 <- svm_fraud[,-11]
fraud_table <- table(svm_fraud_2$fraud)
8213/6354407
```

```{r}
#Training Data model with all data
library(caret)
set.seed(123)
ind = createDataPartition(svm_fraud_2$fraud, p = .8, list = FALSE)
trainset = svm_fraud_2[ind,-10]
testset = svm_fraud_2[-ind,-10]
yvar <- svm_fraud_2[ind, 10]
dim(trainset)
dim(testset)
```

```{r}
#creating new dataset (trying more test samples)
set.seed(456)
downSampleFraud50 <- sample_n(downSampleFraudno, 50000)
downSampleFraud50 <- rbind(downSampleFraud50, fraud_only)
dim(downSampleFraud50)
table(downSampleFraud50$fraud)
8213/58213

#training/test set
set.seed(123)
ind50K = createDataPartition(downSampleFraud50$fraud, p = .8, list = FALSE)
trainset50K = downSampleFraud50[ind50K,]
testset50K = downSampleFraud50[-ind50K,]


dim(trainset50K)
dim(testset50K)
```

```{r}

## Trying Z-NORM ### Min/MAX NORM provided great results but z-normalization was better ###
trainNormZ <- as.data.frame(scale(trainset50K[c(3,5,6,8,9)]))
bindNormZ <- cbind(trainNormZ,
                   type = trainset50K[,2], 
                   transaction_end = trainset50K[,7],
                   fraud = trainset50K[,10])
testNormZ <- as.data.frame(scale(testset50K[c(3,5,6,8,9)]))
testbindNormZ <- cbind(testNormZ,
                       type = testset50K[,2],
                       transaction_end = testset50K[,7],
                       fraud = testset50K[,10])

```

```{r}
### Polynomial 97.43% and an 88.91% kappa. I attempted other cost for polynomial and 1000 was best.
svm_fraud_linear1000Zpoly = svm(fraud ~., 
                             data = bindNormZ, 
                             type = "C-classification",
                             cost = 1000,
                             kernel = "polynomial",
                             scale = FALSE)
svm_fraud_linear1000Zpoly
```

```{r}
test_pred_linear1000Zpoly <- predict(svm_fraud_linear1000Zpoly, newdata = testbindNormZ)
confusionMatrix(test_pred_linear1000Zpoly, testbindNormZ$fraud, positive = "Yes")
```

```{r}
#Appendix below to many other models used to create the best accuracy metrics. Using polynomial kernel and cost of 1000 provided the best model using downsampled data.
```

```{r}
#Model - issues running all data points. SVM could not handle all 6 million data points
library(e1071)
svm_fraud_model = svm(fraud ~., data = svm_fraud_2, scale = FALSE)
```

```{r}
#downsampling non-fraud data points to run SVM and increase fraud percentage
library(dplyr)
downSampleFraudno <- svm_fraud_2 %>% filter(fraud == "No")
fraud_only <- svm_fraud_2 %>% filter(fraud == "Yes")
  #check
dim(fraud_only)
dim(downSampleFraudno)
```

```{r}
  #creating new dataset
set.seed(456)
downSampleFraud <- sample_n(downSampleFraudno, 25000)
downSampleFraud <- rbind(downSampleFraud, fraud_only)
  #High-level EDA on new data set
summary(downSampleFraud)
```

```{r}
  #creating new training data
set.seed(123)
ind = createDataPartition(downSampleFraud$fraud, p = .8, list = FALSE)
trainset = downSampleFraud[ind,]
testset = downSampleFraud[-ind,]

table(testset$fraud)

dim(trainset)
dim(testset)
```

```{r}
#Model 1 - Linear model with cost = 1 --- 81.57%
svm_fraud_linear1 = svm(fraud ~., 
                      data = trainset, 
                      type = "C-classification",
                      cost = 1,
                      kernel = "linear",
                      scale = FALSE)
test_pred_linear1 <- predict(svm_fraud_linear1, newdata = testset)
confusionMatrix(test_pred_linear1, testset$fraud)
```

```{r}
plot(svm_fraud_linear1$SV)
```

```{r}
plot(svm_fraud_linear1$coefs)
```

```{r}
plot(svm_fraud_linear1$decision.values)
```

```{r}
#Model 2 - Linear model with cost = 100
svm_fraud_linear100 = svm(fraud ~., 
                       data = trainset, 
                       type = "C-classification",
                       cost = 100,
                       kernel = "linear",
                       scale = FALSE)
svm_fraud_linear100
```

```{r}
test_pred_linear100 <- predict(svm_fraud_linear100, newdata = testset)
confusionMatrix(test_pred_linear100, testset$fraud)
```

```{r}
#Model 3 - polynomial model with cost = 1
svm_fraud_poly1 = svm(fraud ~., 
                          data = trainset, 
                          type = "C-classification",
                          cost = 1,
                          kernel = "polynomial",
                          scale = FALSE)
svm_fraud_poly1
```

```{r}
test_pred_poly1 <- predict(svm_fraud_poly1, newdata = testset)
confusionMatrix(test_pred_poly1, testset$fraud)
```

```{r}
#Model 4 - polynomial model with cost = 100
svm_fraud_poly100 = svm(fraud ~., 
                      data = trainset, 
                      type = "C-classification",
                      cost = 100,
                      kernel = "polynomial",
                      scale = FALSE)
svm_fraud_poly100
```

```{r}
test_pred_poly100 <- predict(svm_fraud_poly100, newdata = testset)
confusionMatrix(test_pred_poly100, testset$fraud)
```
```{r}
#Model 5 - Radial model with cost = 1
svm_fraud_radial1 = svm(fraud ~., 
                        data = trainset, 
                        type = "C-classification",
                        cost = 1,
                        kernel = "radial",
                        scale = FALSE)
svm_fraud_radial1
```

```{r}
#terrible kappa, radail may not be the best kernel for this dataset. cost was = 1, so may be the cause.
test_pred_radial1 <- predict(svm_fraud_radial1, newdata = testset)
confusionMatrix(test_pred_radial1, testset$fraud)
```

```{r}
#Model 6 - Radial model with cost = 100
svm_fraud_radial100 = svm(fraud ~., 
                        data = trainset, 
                        type = "C-classification",
                        cost = 100,
                        kernel = "radial",
                        scale = FALSE)
svm_fraud_radial100
```

```{r}
test_pred_radial100 <- predict(svm_fraud_radial100, newdata = testset)
confusionMatrix(test_pred_radial100, testset$fraud)
```

```{r}
#Model 7 - Sigmoid model with cost = 1. Sigmoid kernel provided the worst kappa metric.
svm_fraud_sigmoid1 = svm(fraud ~., 
                          data = trainset, 
                          type = "C-classification",
                          cost = 1,
                          kernel = "sigmoid",
                          scale = FALSE)
svm_fraud_sigmoid1
```

```{r}
test_pred_sigmoid1 <- predict(svm_fraud_sigmoid1, newdata = testset)
confusionMatrix(test_pred_sigmoid1, testset$fraud)
```

```{r}
#Model 9 - Sigmoid model with cost = 100
svm_fraud_sigmoid100 = svm(fraud ~., 
                         data = trainset, 
                         type = "C-classification",
                         cost = 100,
                         kernel = "sigmoid",
                         scale = FALSE)
svm_fraud_sigmoid100
```

```{r}
test_pred_sigmoid100 <- predict(svm_fraud_sigmoid100, newdata = testset)
confusionMatrix(test_pred_sigmoid100, testset$fraud)
```

```{r}
#creating new dataset (trying more test samples)
set.seed(456)
downSampleFraud50 <- sample_n(downSampleFraudno, 50000)
downSampleFraud50 <- rbind(downSampleFraud50, fraud_only)
dim(downSampleFraud50)
table(downSampleFraud50$fraud)
8213/58213

  #training/test set
set.seed(123)
ind50K = createDataPartition(downSampleFraud50$fraud, p = .8, list = FALSE)
trainset50K = downSampleFraud50[ind50K,]
testset50K = downSampleFraud50[-ind50K,]


dim(trainset50K)
dim(testset50K)
```

```{r}
#Test model with more data, linear kernel. Slightly better accuracy but kappa is still bad. 
#will attempt norm.
svm_fraud_linear50K = svm(fraud ~., 
                              data = trainset50K, 
                              type = "C-classification",
                              cost = 1,
                              kernel = "linear",
                              scale = FALSE)
svm_fraud_linear50K
```

```{r}
test_pred_linear50K <- predict(svm_fraud_linear50K, newdata = testset50K)
confusionMatrix(test_pred_linear50K, testset50K$fraud, positive = "Yes")
```

```{r}
#min max normalization
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

trainNorm <- as.data.frame(lapply(trainset50K[c(3,5,6,8,9)], normalize))
bind <- cbind(trainNorm,
              type = trainset50K[,2], 
              transaction_end = trainset50K[,7],
              fraud = trainset50K[,10])
testNorm <- as.data.frame(lapply(testset50K[c(3,5,6,8,9)], normalize))
testbind <- cbind(testNorm,
                  type = testset50K[,2],
                  transaction_end = testset50K[,7],
                  fraud = testset50K[,10])
dim(bind)
dim(testbind)
```

```{r}
#Creating new data frame with normalized data above
#Running model with min/max normalized data 

#increased accuracy and kappa, normalizing the data helped

svm_fraud_linear1mmnorm = svm(fraud ~., 
                              data = bind, 
                              type = "C-classification",
                              cost = 1,
                              kernel = "linear",
                              scale = FALSE)
svm_fraud_linear1mmnorm
```

```{r}
test_pred_linear1mmnorm <- predict(svm_fraud_linear1mmnorm, newdata = testbind)
confusionMatrix(test_pred_linear1mmnorm, testbind$fraud)
```

```{r}
svm_fraud_linear100mmnorm = svm(fraud ~., 
                              data = bind, 
                              type = "C-classification",
                              cost = 100,
                              kernel = "sigmoid",
                              scale = FALSE)
svm_fraud_linear100mmnorm
```

```{r}
test_pred_linear100mmnorm <- predict(svm_fraud_linear100mmnorm, newdata = testbind)
confusionMatrix(test_pred_linear100mmnorm, testbind$fraud)
```
```{r}
 ## Trying Z-normalization    
trainNormZ <- as.data.frame(scale(trainset50K[c(3,5,6,8,9)]))
bindNormZ <- cbind(trainNormZ,
              type = trainset50K[,2], 
              transaction_end = trainset50K[,7],
              fraud = trainset50K[,10])
testNormZ <- as.data.frame(scale(testset50K[c(3,5,6,8,9)]))
testbindNormZ <- cbind(testNormZ,
                  type = testset50K[,2],
                  transaction_end = testset50K[,7],
                  fraud = testset50K[,10])
```

```{r}
#### Model with z normalization 96.2% !!!!
svm_fraud_linear100Znorm = svm(fraud ~., 
                                    data = bindNormZ, 
                                    type = "C-classification",
                                    cost = 100,
                                    kernel = "linear",
                                    scale = FALSE)
svm_fraud_linear100Znorm
```

```{r}
test_pred_linear100Znorm <- predict(svm_fraud_linear100Znorm, newdata = testbindNormZ)
confusionMatrix(test_pred_linear100Znorm, testbindNormZ$fraud)
```

```{r}
### 96.42% best so far.
svm_fraud_linear10Znorm = svm(fraud ~., 
                               data = bindNormZ, 
                               type = "C-classification",
                               cost = 10,
                               kernel = "linear",
                               scale = FALSE)
svm_fraud_linear10Znorm
```

```{r}
test_pred_linear10Znorm <- predict(svm_fraud_linear10Znorm, newdata = testbindNormZ)
confusionMatrix(test_pred_linear10Znorm, testbindNormZ$fraud)
```

```{r}
### sigmoid. Accruacy and kappa decreased
svm_fraud_linear10Zsig = svm(fraud ~., 
                              data = bindNormZ, 
                              type = "C-classification",
                              cost = 10,
                              kernel = "sigmoid",
                              scale = FALSE)
svm_fraud_linear10Zsig
```

```{r}
test_pred_linear10Zsig <- predict(svm_fraud_linear10Zsig, newdata = testbindNormZ)
confusionMatrix(test_pred_linear10Zsig, testbindNormZ$fraud)
```

```{r}
### radial 96.56%
svm_fraud_linear10Zrad = svm(fraud ~., 
                             data = bindNormZ, 
                             type = "C-classification",
                             cost = 10,
                             kernel = "radial",
                             scale = FALSE)
svm_fraud_linear10Zrad
```

```{r}
test_pred_linear10Zrad <- predict(svm_fraud_linear10Zrad, newdata = testbindNormZ)
confusionMatrix(test_pred_linear10Zrad, testbindNormZ$fraud)
```

```{r}

```

```{r}

```

```{r}

```

